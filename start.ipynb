{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel & MobileODT Cervical Cancer Screening\n",
    "\n",
    "I am working on this project for a Kaggle competition:\n",
    "\n",
    "https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening\n",
    "\n",
    "My goal is accurately identifie a woman’s cervix type (type 1, type 2 or type 3) based on the image. As a rtaning set I am using about 1500 images (about 500 images for every type of cancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR1 = 'train/Type_1'\n",
    "TRAIN_DIR2 = 'train/Type_2'\n",
    "TRAIN_DIR3 = 'train/Type_3'\n",
    "TEST_DIR = 'test'\n",
    "IMG_SIZE = 50 # The photos have different size. I will resize it 50 by 50 just to start (I think, we need to use a better resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_depth = 255.0 \n",
    "def create_train_data(TRAIN_DIR, label):\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        if not img[0].isdigit():\n",
    "            continue\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = (cv2.imread(path,cv2.IMREAD_GRAYSCALE) - pixel_depth / 2) / pixel_depth\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [01:07<00:00,  4.21it/s]\n",
      "100%|██████████| 772/772 [03:42<00:00,  4.04it/s]\n",
      "100%|██████████| 441/441 [02:06<00:00,  4.07it/s]\n"
     ]
    }
   ],
   "source": [
    "create_train_data(TRAIN_DIR1, [1.0,0.0,0.0])\n",
    "create_train_data(TRAIN_DIR2, [0.0,1.0,0.0])\n",
    "create_train_data(TRAIN_DIR3, [0.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(training_data)\n",
    "np.save('train_data_50_50_gray.npy', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('train_data_50_50_gray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:-250]\n",
    "valid = train_data[-250: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = np.array([i[1] for i in train])\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = np.array([i[1] for i in test])\n",
    "\n",
    "valid_x = np.array([i[0] for i in valid]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "valid_y = np.array([i[1] for i in valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test_x.reshape((-1, IMG_SIZE * IMG_SIZE)).astype(np.float32)\n",
    "valid_x = valid_x.reshape((-1, IMG_SIZE * IMG_SIZE)).astype(np.float32)\n",
    "X = X.reshape((-1, IMG_SIZE * IMG_SIZE)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 50\n",
    "num_labels = 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_x)\n",
    "    tf_test_dataset = tf.constant(test_x)\n",
    "    #tf_result_dataset = tf.constant(test_pictures)\n",
    "\n",
    "    num_hidden_nodes = 1554\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset,weights1)+biases1)\n",
    "    logits = tf.matmul(layer_1, weights2) + biases2\n",
    "    \n",
    "    betta = 0.01\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, \n",
    "        logits=logits) + betta *(tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights2)\n",
    "                                 + tf.nn.l2_loss(biases2)))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights1)+biases1),weights2) + biases2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights1)+biases1),weights2) + biases2)\n",
    "    #result = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_result_dataset, weights1)+biases1),weights2) + biases2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (951, 2500) (951, 3)\n",
      "Validation set (250, 2500) (250, 3)\n",
      "Test set (250, 2500) (250, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X.shape, Y.shape)\n",
    "print('Validation set', valid_x.shape, valid_y.shape)\n",
    "print('Test set', test_x.shape, test_y.shape)\n",
    "#print('Result set', test_pictures.shape, test_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-ec4fcc7fb97a>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Two layers netowrk, Initialized\n",
      "Minibatch loss at step 0: 15271.484375\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 52.4%\n",
      "Minibatch loss at step 20: 12428.231445\n",
      "Minibatch accuracy: 46.1%\n",
      "Validation accuracy: 46.8%\n",
      "Minibatch loss at step 40: 10106.538086\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 41.2%\n",
      "Minibatch loss at step 60: 8258.040039\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 80: 6753.188965\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 50.0%\n",
      "Minibatch loss at step 100: 5525.763184\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 120: 4522.470215\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 52.4%\n",
      "Minibatch loss at step 140: 3700.548828\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 50.0%\n",
      "Minibatch loss at step 160: 3028.262207\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 49.6%\n",
      "Minibatch loss at step 180: 2478.208252\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 50.4%\n",
      "Minibatch loss at step 200: 2027.955078\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 50.4%\n",
      "Minibatch loss at step 220: 1659.528809\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 50.8%\n",
      "Minibatch loss at step 240: 1358.060913\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 49.6%\n",
      "Minibatch loss at step 260: 1111.339111\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 280: 909.467407\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 300: 744.313477\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 320: 609.106628\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 340: 498.502441\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 45.2%\n",
      "Minibatch loss at step 360: 408.083252\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 48.4%\n",
      "Minibatch loss at step 380: 334.104736\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 44.4%\n",
      "Minibatch loss at step 400: 273.371613\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 56.0%\n",
      "Minibatch loss at step 420: 223.741058\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 50.0%\n",
      "Minibatch loss at step 440: 183.241211\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 54.0%\n",
      "Minibatch loss at step 460: 150.011047\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 52.8%\n",
      "Minibatch loss at step 480: 123.050354\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 52.8%\n",
      "Minibatch loss at step 500: 100.650696\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 520: 82.425056\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 540: 67.739777\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 52.8%\n",
      "Minibatch loss at step 560: 55.868900\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 41.6%\n",
      "Minibatch loss at step 580: 45.720581\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 600: 37.523766\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 620: 30.720203\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 640: 25.274385\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 50.8%\n",
      "Minibatch loss at step 660: 20.987865\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 680: 17.358006\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 42.8%\n",
      "Minibatch loss at step 700: 14.226562\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 720: 12.046402\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 740: 9.936938\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 40.8%\n",
      "Minibatch loss at step 760: 8.196836\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 780: 6.930248\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 50.0%\n",
      "Minibatch loss at step 800: 5.752202\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 820: 4.654537\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 48.4%\n",
      "Minibatch loss at step 840: 4.231336\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 860: 3.590334\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 46.0%\n",
      "Minibatch loss at step 880: 2.945901\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 900: 2.728173\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 920: 2.652524\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 45.2%\n",
      "Minibatch loss at step 940: 3.137094\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 960: 2.084516\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 49.6%\n",
      "Minibatch loss at step 980: 1.556271\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 42.0%\n",
      "Minibatch loss at step 1000: 1.473692\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 1020: 1.641025\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 1040: 1.491771\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 45.2%\n",
      "Minibatch loss at step 1060: 1.316553\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 46.0%\n",
      "Minibatch loss at step 1080: 1.220849\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 1100: 1.034398\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 1120: 1.209539\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 52.4%\n",
      "Minibatch loss at step 1140: 1.115749\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 47.2%\n",
      "Minibatch loss at step 1160: 0.913831\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 46.0%\n",
      "Minibatch loss at step 1180: 0.792780\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 1200: 0.979235\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 1220: 0.889139\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 1240: 0.861288\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 1260: 1.085465\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 1280: 0.884734\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 43.6%\n",
      "Minibatch loss at step 1300: 0.951572\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 50.8%\n",
      "Minibatch loss at step 1320: 0.776947\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 1340: 0.736374\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 50.8%\n",
      "Minibatch loss at step 1360: 0.851342\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 50.0%\n",
      "Minibatch loss at step 1380: 0.893285\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 46.8%\n",
      "Minibatch loss at step 1400: 0.724648\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 42.0%\n",
      "Minibatch loss at step 1420: 0.779576\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 42.8%\n",
      "Minibatch loss at step 1440: 0.880260\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 1460: 0.795330\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 47.2%\n",
      "Minibatch loss at step 1480: 1.008899\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 46.0%\n",
      "Minibatch loss at step 1500: 0.793526\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 42.4%\n",
      "Minibatch loss at step 1520: 0.743079\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 38.8%\n",
      "Minibatch loss at step 1540: 0.666730\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 44.8%\n",
      "Minibatch loss at step 1560: 0.730526\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 42.4%\n",
      "Minibatch loss at step 1580: 0.925979\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 1600: 0.748162\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 1620: 0.921150\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 46.8%\n",
      "Minibatch loss at step 1640: 0.856057\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 42.8%\n",
      "Minibatch loss at step 1660: 0.785844\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 40.4%\n",
      "Minibatch loss at step 1680: 0.692165\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 46.0%\n",
      "Minibatch loss at step 1700: 0.938305\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 35.6%\n",
      "Minibatch loss at step 1720: 0.733699\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 51.6%\n",
      "Minibatch loss at step 1740: 0.767078\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 44.8%\n",
      "Minibatch loss at step 1760: 0.894412\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 43.2%\n",
      "Minibatch loss at step 1780: 0.738765\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 44.0%\n",
      "Minibatch loss at step 1800: 0.869286\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 44.4%\n",
      "Minibatch loss at step 1820: 0.896405\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 44.8%\n",
      "Minibatch loss at step 1840: 0.845498\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 46.8%\n",
      "Minibatch loss at step 1860: 0.765660\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 1880: 0.699073\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 47.2%\n",
      "Minibatch loss at step 1900: 0.718770\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 50.0%\n",
      "Minibatch loss at step 1920: 0.797141\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 1940: 0.698991\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 41.2%\n",
      "Minibatch loss at step 1960: 0.683039\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 43.6%\n",
      "Minibatch loss at step 1980: 0.783682\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 43.2%\n",
      "Minibatch loss at step 2000: 0.801122\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 43.2%\n",
      "Test accuracy: 37.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 2001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\ttf.initialize_all_variables().run()\n",
    "\tprint(\"Two layers netowrk, Initialized\")\n",
    "\tfor step in range(num_steps):\n",
    "\t\toffset = (step * batch_size) % (Y.shape[0] - batch_size)\n",
    "\t\tbatch_data = X[offset:(offset + batch_size), :]\n",
    "\t\tbatch_labels = Y[offset:(offset + batch_size), :]\n",
    "\t\tfeed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "\t\t_, l, predictions = session.run(\n",
    "\t\t\t[optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\t\tif (step % 20 == 0):\n",
    "\t\t\tprint(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "\t\t\tprint(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            \n",
    "\t\t\tprint(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_y))\n",
    "            #print(\"Log_loss:\", metrics.log_loss(valid_y, valid_prediction))           \n",
    "\tprint(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_y))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that validation accuracy decreases after step 1000 and that test accuracy and validation accuracy are almost equal. Thus, I am goint to try to do 1001 steps only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-f966112a1c79>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Two layers netowrk, Initialized\n",
      "Minibatch loss at step 0: 15268.683594\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 50.8%\n",
      "Minibatch loss at step 500: 100.725555\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 40.0%\n",
      "Minibatch loss at step 1000: 1.378992\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 50.0%\n",
      "Test accuracy: 47.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\ttf.initialize_all_variables().run()\n",
    "\tprint(\"Two layers netowrk, Initialized\")\n",
    "\tfor step in range(num_steps):\n",
    "\t\toffset = (step * batch_size) % (Y.shape[0] - batch_size)\n",
    "\t\tbatch_data = X[offset:(offset + batch_size), :]\n",
    "\t\tbatch_labels = Y[offset:(offset + batch_size), :]\n",
    "\t\tfeed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "\t\t_, l, predictions = session.run(\n",
    "\t\t\t[optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\t\tif (step % 500 == 0):\n",
    "\t\t\tprint(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "\t\t\tprint(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "\t\t\tprint(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "\t\t\t\tvalid_prediction.eval(), valid_y))\n",
    "\tprint(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47.6 is not super good, but is is better than 33% that we can get if we will predit always the same type.\n",
    "\n",
    "Now, I am going to try increase the picture size up to 100 by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [01:19<00:00,  3.93it/s]\n",
      "100%|██████████| 782/782 [03:54<00:00,  4.36it/s]\n",
      "100%|██████████| 451/451 [01:50<00:00,  4.63it/s]\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 100\n",
    "\n",
    "training_data = []\n",
    "create_train_data(TRAIN_DIR1, [1.0,0.0,0.0])\n",
    "create_train_data(TRAIN_DIR2, [0.0,1.0,0.0])\n",
    "create_train_data(TRAIN_DIR3, [0.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(training_data)\n",
    "np.save('train_data_100_100_gray.npy', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('train_data_100_100_gray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:-250]\n",
    "valid = train_data[-250: ]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = np.array([i[1] for i in train])\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = np.array([i[1] for i in test])\n",
    "\n",
    "valid_x = np.array([i[0] for i in valid]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "valid_y = np.array([i[1] for i in valid])\n",
    "\n",
    "test_x = test_x.reshape((-1, IMG_SIZE * IMG_SIZE)).astype(np.float32)\n",
    "valid_x = valid_x.reshape((-1, IMG_SIZE * IMG_SIZE)).astype(np.float32)\n",
    "X = X.reshape((-1, IMG_SIZE * IMG_SIZE)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 100\n",
    "num_labels = 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_x)\n",
    "    tf_test_dataset = tf.constant(test_x)\n",
    "\n",
    "    num_hidden_nodes = 1554\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset,weights1)+biases1)\n",
    "    logits = tf.matmul(layer_1, weights2) + biases2\n",
    "    \n",
    "    betta = 0.01\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, \n",
    "        logits=logits) + betta *(tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights2)\n",
    "                                 + tf.nn.l2_loss(biases2)))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights1)+biases1),weights2) + biases2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights1)+biases1),weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (981, 10000) (981, 3)\n",
      "Validation set (250, 10000) (250, 3)\n",
      "Test set (250, 10000) (250, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X.shape, Y.shape)\n",
    "print('Validation set', valid_x.shape, valid_y.shape)\n",
    "print('Test set', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-13f45ba3b1e9>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Two layers netowrk, Initialized\n",
      "Minibatch loss at step 0: 60470.289062\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 55.2%\n",
      "Minibatch loss at step 500: 414.891235\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 1000: 4.122334\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 1500: 1.744074\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 42.0%\n",
      "Minibatch loss at step 2000: 1.140596\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 41.6%\n",
      "Minibatch loss at step 2500: 0.922524\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 3000: 0.827986\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 51.2%\n",
      "Test accuracy: 45.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\ttf.initialize_all_variables().run()\n",
    "\tprint(\"Two layers netowrk, Initialized\")\n",
    "\tfor step in range(num_steps):\n",
    "\t\toffset = (step * batch_size) % (Y.shape[0] - batch_size)\n",
    "\t\tbatch_data = X[offset:(offset + batch_size), :]\n",
    "\t\tbatch_labels = Y[offset:(offset + batch_size), :]\n",
    "\t\tfeed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "\t\t_, l, predictions = session.run(\n",
    "\t\t\t[optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\t\tif (step % 500 == 0):\n",
    "\t\t\tprint(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "\t\t\tprint(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "\t\t\tprint(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "\t\t\t\tvalid_prediction.eval(), valid_y))\n",
    "\tprint(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The better resolution did not give me the better result.\n",
    "\n",
    "\n",
    "I have used the photos in grayscale. I think, the colors can be important for this problem since it looks like pictures of Type 1 have more red aread than of Type 2 and 3. Thus, I am going to try COLOR_BGR2RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0 \n",
    "def create_train_data(TRAIN_DIR, label):\n",
    "    count = 0\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        if not img[0].isdigit():\n",
    "            continue\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = (cv2.imread(path,cv2.COLOR_BGR2RGB) - pixel_depth / 2) / pixel_depth\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "        count +=1\n",
    "    print(TRAIN_DIR, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [03:24<00:00,  1.60it/s]\n",
      "100%|██████████| 782/782 [09:45<00:00,  1.59it/s]\n",
      "100%|██████████| 451/451 [04:47<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 50\n",
    "\n",
    "training_data = []\n",
    "create_train_data(TRAIN_DIR1, [1.0,0.0,0.0])\n",
    "create_train_data(TRAIN_DIR2, [0.0,1.0,0.0])\n",
    "create_train_data(TRAIN_DIR3, [0.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(training_data)\n",
    "np.save('train_data_50_50_color.npy', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('train_data_50_50_color.npy')\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:-250]\n",
    "valid = train_data[-250: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "Y = np.array([i[1] for i in train])\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "test_y = np.array([i[1] for i in test])\n",
    "\n",
    "valid_x = np.array([i[0] for i in valid]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "valid_y = np.array([i[1] for i in valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 50, 50, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test_x.reshape((-1, IMG_SIZE * IMG_SIZE * 3)).astype(np.float32)\n",
    "valid_x = valid_x.reshape((-1, IMG_SIZE * IMG_SIZE * 3)).astype(np.float32)\n",
    "X = X.reshape((-1, IMG_SIZE * IMG_SIZE * 3)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (981, 7500) (981, 3)\n",
      "Validation set (250, 7500) (250, 3)\n",
      "Test set (250, 7500) (250, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X.shape, Y.shape)\n",
    "print('Validation set', valid_x.shape, valid_y.shape)\n",
    "print('Test set', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 50\n",
    "num_labels = 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size * 3))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_x)\n",
    "    tf_test_dataset = tf.constant(test_x)\n",
    "    \n",
    "    num_hidden_nodes = 1554\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size * 3, num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset,weights1)+biases1)\n",
    "    logits = tf.matmul(layer_1, weights2) + biases2\n",
    "    \n",
    "    betta = 0.01\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, \n",
    "        logits=logits) + betta *(tf.nn.l2_loss(weights1) + tf.nn.l2_loss(biases1) + tf.nn.l2_loss(weights2)\n",
    "                                 + tf.nn.l2_loss(biases2)))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights1)+biases1),weights2) + biases2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights1)+biases1),weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-50-13f45ba3b1e9>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Two layers netowrk, Initialized\n",
      "Minibatch loss at step 0: 45411.992188\n",
      "Minibatch accuracy: 35.9%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 500: 303.543274\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 1000: 3.095729\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 48.4%\n",
      "Minibatch loss at step 1500: 1.043535\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 2000: 0.873229\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 42.8%\n",
      "Minibatch loss at step 2500: 0.995510\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 38.8%\n",
      "Minibatch loss at step 3000: 0.863765\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 40.8%\n",
      "Test accuracy: 39.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\ttf.initialize_all_variables().run()\n",
    "\tprint(\"Two layers netowrk, Initialized\")\n",
    "\tfor step in range(num_steps):\n",
    "\t\toffset = (step * batch_size) % (Y.shape[0] - batch_size)\n",
    "\t\tbatch_data = X[offset:(offset + batch_size), :]\n",
    "\t\tbatch_labels = Y[offset:(offset + batch_size), :]\n",
    "\t\tfeed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "\t\t_, l, predictions = session.run(\n",
    "\t\t\t[optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\t\tif (step % 500 == 0):\n",
    "\t\t\tprint(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "\t\t\tprint(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "\t\t\tprint(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "\t\t\t\tvalid_prediction.eval(), valid_y))\n",
    "\tprint(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that I had the highest accuracy after the first step. Thus I will try to run the same algoritm with less steps: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-51-ab2e1dba1191>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Two layers netowrk, Initialized\n",
      "Minibatch loss at step 0: 45459.871094\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 17.2%\n",
      "Minibatch loss at step 20: 37474.875000\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 40: 30587.208984\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 60: 25029.021484\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 50.4%\n",
      "Minibatch loss at step 80: 20482.097656\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 46.8%\n",
      "Minibatch loss at step 100: 16760.386719\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 120: 13715.205078\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 44.8%\n",
      "Minibatch loss at step 140: 11223.781250\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 43.6%\n",
      "Minibatch loss at step 160: 9184.925781\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 180: 7516.029297\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 200: 6150.630859\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 220: 5033.438477\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 240: 4118.894531\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 46.4%\n",
      "Minibatch loss at step 260: 3370.587646\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 280: 2758.407715\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 45.2%\n",
      "Minibatch loss at step 300: 2257.365234\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 46.0%\n",
      "Minibatch loss at step 320: 1847.298950\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 45.6%\n",
      "Minibatch loss at step 340: 1511.751099\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 46.8%\n",
      "Minibatch loss at step 360: 1237.201416\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 48.8%\n",
      "Minibatch loss at step 380: 1012.542603\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 400: 828.715332\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 45.2%\n",
      "Minibatch loss at step 420: 678.233337\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 50.8%\n",
      "Minibatch loss at step 440: 555.196106\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 460: 454.354431\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 480: 372.020508\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 50.0%\n",
      "Test accuracy: 49.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 500\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\ttf.initialize_all_variables().run()\n",
    "\tprint(\"Two layers netowrk, Initialized\")\n",
    "\tfor step in range(num_steps):\n",
    "\t\toffset = (step * batch_size) % (Y.shape[0] - batch_size)\n",
    "\t\tbatch_data = X[offset:(offset + batch_size), :]\n",
    "\t\tbatch_labels = Y[offset:(offset + batch_size), :]\n",
    "\t\tfeed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "\t\t_, l, predictions = session.run(\n",
    "\t\t\t[optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\t\tif (step % 20 == 0):\n",
    "\t\t\tprint(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "\t\t\tprint(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "\t\t\tprint(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "\t\t\t\tvalid_prediction.eval(), valid_y))\n",
    "\tprint(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Using the full color pictures works better than grayscale. The next step could be increasing the size of the photos and increasing the number of training examples, but, unfortunately, the memory limitation of my machine does not permit me to try that."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
